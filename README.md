# Doc2VecFacil

Componente python que simplifica o processo de cria√ß√£o de um modelo `Doc2Vec` [`Gensim 4.0.1`](https://radimrehurek.com/gensim/) com facilitadores para gera√ß√£o de um vocab personalizado e com a gera√ß√£o de arquivos de curadoria.
- se voc√™ n√£o sabe o que √© um modelo de similaridade, em resumo √© um algoritmo n√£o supervisionado para transformar frases ou documentos em vetores matem√°ticos que podem ser comparados retornando um valor que representa a similaridade sem√¢ntica entre dois ou mais documentos. Nesse contexto a m√°quina 'aprende' o vocabul√°rio treinado e o contexto em que as palavras aparecem, permitindo identificar a similaridade entre os termos, as frases e os documentos.
- Com essa compara√ß√£o vetorial, √© poss√≠vel encontrar documentos semelhantes a um indicado, agrupar documentos semelhantes de uma lista de documentos e monitorar documentos que entram na base ao compar√°-los com os documentos marcados como importantes para monitoramento. 
- Esse √© um reposit√≥rio de estudos, analise, ajuste, corrija e use os c√≥digos como desejar.

### Esse componente `Doc2VecFacil` trabalha em duas etapas:
 - cria√ß√£o de um vocab personalizado ao processar textos considerados importantes para o modelo que ser√° treinado
   - `python util_doc2vec_vocab_facil.py -pasta ./meu_modelo`
 - treinamento do modelo usando a estrutura de tokeniza√ß√£o criada manualmente ou a partir do c√≥digo acima
   - `python util_doc2vec_facil.py -pasta ./meu_modelo` -treinar

 - Aqui tem um passo a passo simplificado: [`Passo a Passo`](passo_a_passo_facil.md)
 - Logo abaixo est√£o as explica√ß√µes detalhadas de como ele funciona e como usar o seu modelo para pesquisas de documentos semelhantes semanticamente ou textualmente, como realizar agrupamento de documentos por similaridade para auxiliar na organiza√ß√£o de documentos usando o ElasticSearch e a pesquisa vetorial.

- :page_with_curl: <b>C√≥digos</b>: 
  - [`Cria√ß√£o de vocab`](./src/util_doc2vec_vocab_facil.py)
  - [`UtilDoc2VecFacil`](./src/util_doc2vec_facil.py) e [`UtilDoc2VecFacil_Treinamento`](./src/util_doc2vec_facil.py) 
  - [`TradutorTermos`](./src/util_tradutor_termos.py)
  - [`Cria√ß√£o de ngramas`](./src/util_ngramas_facil.py) dicas aqui [NGramasFacil](readme_ngramas.md)

`EM BREVE`: Ser√° disponibilizado um servi√ßo exemplo em conjunto com o componente [PesquisaElasticFacil](https://github.com/luizanisio/PesquisaElasticFacil) para cria√ß√£o de modelos de similaridade textual, agregando valor √†s pesquisas do ElasticSearch de forma simples com um modelo treinado no corpus espec√≠fico de cada projeto.

## Cria√ß√£o do vocab personalizado

O arquivo `util_doc2vec_vocab_facil.py` √© complementar √† classe `Doc2VecFacil` e serve para facilitar a cria√ß√£o de arquivos que configuram o `TokenizadorInteligente`. A ideia √© trabalhar com termos importantes para o modelo, adicionados a termos complementares compostos por fragmentos de termos `stemmer` + `sufixo`. Com isso novos documentos que possuam termos fora do vocab principal podem ter o stemmer e o sufixo dentro do vocab do modelo, criando um vocab mais flex√≠vel e menor. √â poss√≠vel tamb√©m transformar termos ou conjunto de termos durante o processamento, como criar n-gramas, reduzir nomes de organiza√ß√µes em sigla, remover termos simples ou compostos etc.

### Arquivo de curadoria para cria√ß√£o do vocab
 - Ser√° criado um arquivo de curadoria `curadoria_planilha_vocab.xlsx` com os termos encontrados nos textos da pasta `textos_vocab`. 
   - coloque aqui textos que contenham boas palavras, limpas de prefer√™ncia. Podem ser listas retiradas de algum documento, n√£o importa o contexto delas, apenas as palavras nessa primeira etapa. Ent√£o listas de palavras e documentos como gram√°ticas e dicion√°rios de portugu√™s digitais parecem uma boa op√ß√£o. Coloque tamb√©m documentos com palavras relacionadas ao corpus desejado (psicologia, medicina, legisla√ß√£o, administra√ß√£o, etc). Esse site permite uma an√°lise muito boa de termos e suas caracter√≠sticas [Dicio](https://www.dicio.com.br/).
 - Alguns termos podem n√£o ser t√£o importantes para o dom√≠nio escolhido, mas podem ser importantes para o contexto. Esses termos podem compor o dicion√°rio em forma de `stemmer` + `sufixo`. Aos termos n√£o encontrados no dicion√°rio durante a tokeniza√ß√£o para treinamento, ser√° aplicado o stemmer com o sufixo ap√≥s o stemmer. Caso o stemmer esteja no vocab de treinamento, este ser√° usado. O sufixo √© opcional e ser√° inclu√≠do se estiver no vocab de treinamento tamb√©m.
 - Essa combina√ß√£o de termos completos e fragmentos (stemmer + sufixo) possibilita criar palavras por combina√ß√£o ao submeter um documento novo ao modelo que contenha termos fora do vocam de treinamento.
   
 - <b>Exemplo</b>: `engloba` pode ser composta por `englob` `#a`, e outras forma√ß√µes podem ocorrer como `englob` `#ada`, `englob` `#adamente`, `englob` `#adas` caso esses  fragmentos estejam dispon√≠veis no vocabul√°rio de treinamento.
   - O vocab de treinamento n√£o precisa do `#` antes do sufixo, apenas dos fragmentos. Mas durante o treinamento os fragmentos usados como sufixo iniciar√£o com `#` para facilitar sua identifica√ß√£o e diferenciar dos termos principais no modelo final.
 - <b>Exemplo de tokeniza√ß√£o</b>: 
   ```python
   # para carregar o modelo, indique a pasta criada no treinamento
   dv = UtilDoc2VecFacil(pasta_modelo='./meu_modelo_treinado')
   print(dv.tokens_sentenca('ATENDIAM A TESTEMUNHA SEU DEPOIMENTO APESAR DE TRAZER ALGUMAS IMPRECIS√ïES SOBRE OS FATOS ATENDO-SE OS JURADOS √ÄS PROVAS PRODUZIDAS EM PLEN√ÅRIOS'))
   ```
   ```
   ['atendiam_testemunha', 'seu', 'depoimento', 'apesar', 'de', 'trazer', 'algumas', 'impreciso', '#es', 'sobre', 'os', 'fatos', 'atend', '#o', 'se', 'os', 'jurados', 'as', 'provas', 'produzidas', 'em', 'plenari', '#os']
   ```
- Veja o [`passo a passo`](passo_a_passo_facil.md) para criar o vocabul√°rio de treinamento de acordo com o cen√°rio desejado.
- O arquivo `curadoria_planilha_vocab.xlsx` tem todos os termos encontrados nos textos da pasta `textos_vocab`, suas frequ√™ncias, tfidf, tamanho, dentre outros atributos para permitir uma an√°lise e curadoria dos termos. Esse arquivo pode ser aberto no Excel para facilitar a an√°lise/curadoria do vocabul√°rio que ser√° treinado.

- Como funciona o TokenizadorInteligente:
  - Ao ser instanciado, o tokenizador busca os termos do vocab de treinamento contidos nos arquivos com padr√£o `VOCAB_BASE*.txt` (n√£o importa o case).
  - Podem existir listas de termos que ser√£o exclu√≠dos do treinamento, basta esterem em arquivos com o padr√£o `VOCAB_REMOVIDO*.txt`.
  - Podem existir transformadores de termos nos arquivos com o padr√£o `VOCAB_TRADUTOR*.txt` que podem conter termos simples ou compostos que ser√° convertidos em outros termos simples ou compostos, como ngramas por exempo. Veja [`NGramasFacil`](readme_ngramas.md) para mais detalhes.
  - Os tradutores funcionam ap√≥s a limpeza do texto e transformam termos de acordo com a configura√ß√£o no arquivo:
    - `termo1 => termo2` - converte o `termo1` em `termo2` quando encontrado no texto (ex. `min => ministro`)
    - `termo1 termo2 => termo1_termo2` - converte o termo composto `termo1 termo2` em um termo √∫nico `termo1_termo2` (Ex. `processo penal => processo_penal`)
    - `termo1 termo2` - remove o termo composto `termo1 termo2` (Ex. `documento digital => ` ou `documento digital`)
  - Os tradutores podem ser usados para converter nomes de organiza√ß√µes em suas siglas, termos compostos em um termo √∫nicos (ngramas) e at√© termos conhecidos como id√™nticos em sua forma mais usual.
> üí° A ideia de criar v√°rios arquivos √© para organizar por dom√≠nios. Pode-se, por exemplo, criar um arquivo `VOCAB_BASE portugues.txt` com termos que far√£o parte de v√°rios modelos, um arquivo `VOCAB_BASE direito.txt` com termos do direito que ser√£o somados ao primeiro no treinamento, um arquivo `VOCAB_BASE direito fragmentos.txt` com fragmentos (`stemmer` + `sufixos`) de termos do direito, e assim por diante. Facilitando evolu√ß√µes futuras dos vocabul√°rios.

- √â importante ressaltar que quanto maior o n√∫mero de termos, maior o tempo de processamento, mesmo usando recursos otimizados para essa transforma√ß√£o (veja a classe `TradutorTermos` no arquivo [`util_tradutor_termos.py`](./src/util_tradutor_termos.py) ). 
  - Est√° dispon√≠vel um gerador de bigramas e quadrigramas aqui [`NGramasFacil`](readme_ngramas.md) para gerar sugest√µes autom√°ticas de termos que podem ser unificados.
> üí° A ideia de criar v√°rios arquivos √© para organizar por dom√≠nios. Pode-se, por exemplo, criar um arquivo VOCAB_BASE_portugues.txt com termos que far√£o parte de v√°rios modelos, um arquivo VOCAB_BASE_direito.txt com termos do direito que ser√£o somados ao primeiro no treinamento, um arquivo VOCAB_COMPLEMENTAR_direito.txt com fragmentos (`stemmer` + `sufixos`) de termos do direito, e assim por diante.

### Exemplo de arquivo `curadoria_planilha_vocab.xlsx` de curadoria de termos:
| TERMO                  | QUEBRADO         | TFIDF   | TAMANHO |  QTD  | QTD_DOCS | COMPOSTO | VOCAB | VOCAB_QUEBRADOS | ESTRANHO |
|------------------------|------------------|:-------:|:-------:|:-----:|:--------:|:--------:|:------|:---------------:|:--------:|
| acao_penal             |                  | 0,37127 |   	30	  |  178  |   	44	   |    S     |  	S   |        N        |    N     |
| adaptacao              | adaptaca o       | 0,30105 |    10   |   91  |    28    |    N     |   S   |        N        |    N     |
| advogado               | advog ado        | 0,49000 |    7    |  1736 |    810   |    N     |   S   |        N        |    N     |
| custas                 | cust as          | 0,41286 |    6    |  740  |    417   |    N     |   S   |        N        |    N     |
| materia_constitucional	|                  | 0,20749 |   	22	  |   8   |    	2	   |    S	    |   S   |       	N        |    N     |

> üí° Notas sobre as colunas: 
> - `TFIDF` - cont√©m o maior peso que o termo teve dentre os pesos que teve nos documentos - [Saiba mais sobre `TFIDF`](https://www.ti-enxame.com/pt/python/interpretar-um-resumo-das-pontuacoes-das-palavras-do-tf-idf-nos-documentos/829990829/)
> - `TAMANHO` - √© o tamanho do termo
> - `QTD` - √© a quantidade de vezes que o termo apareceu no corpus
> - `QTD_DOCS` - √© a quantidade de documentos onde o termo apareceu
> - `COMPOSTO` Sim / N√£o - indica se o termo √© composto 
> - `VOCAB` Sim / N√£o - indica se o termo est√° presente no vocab principal
> - `VOCAB_QUEBRADOS` Sim / N√£o - indica se pelo menos o stemmer do termo est√° presente no vocab principal
> - `ESTRANHO` Sim / N√£o - termos sem vogais ou com consoantes com v√°rias repeti√ß√µes

## Defini√ß√£o de pastas:
 A estrutura de pastas √© pr√©-definida para facilitar o uso dos componentes. <br>
 O √∫nico par√¢metro informado √© a pasta raiz que vai conter as outras pastas. <br>
 - :file_folder: `Pasta raiz` (informada no par√¢metro da chamada - padr√£o = "meu_modelo")
   - :file_folder: `doc2vecfacil` (pasta do modelo): ao disponibilizar o modelo para uso, pode-se renomear essa pasta livremente
   - :file_folder: `textos_vocab`: textos que ser√£o tokenizados para cria√ß√£o do vocab principal
   - :file_folder: `textos_complementares`: textos que ser√°o tokenizados para cria√ß√£o do dicion√°rio complementar de fragmentos dos termos n√£o encontrados no vocab principal.


## Passo a passo para criar o vocab de treino: 
 1) Criar as pastas:
    - :file_folder: `meu_modelo`
      - :file_folder: `textos_vocab`: colocar um conjunto de textos importantes para o corpus
      - :file_folder: `textos_vocab_complementar`: colocar um conjunto de textos complementares (tokens ser√£o quebrados)
      - :file_folder: `textos_treino`: colocar os arquivos que ser√£o usados no treinamento
 2) Rodar: `python util_doc2vec_vocab_facil.py -pasta./meu_modelo`
    - para forcar recriar os arquivos se j√° existirem, basta colocar o par√¢metro `-reiniciar`
    - ao chamar uma segunda vez, o c√≥digo vai apenas atualizar o arquivo de curadoria
    - o arquivo de curadoria ser√° criado considerando os textos da pasta `textos_treino` tamb√©m
 3) Opcional: abrir o arquivo ./meu_modelo/doc2vecfacil/curadoria_vocab.txt no excel e analisar os termos
    - alterar os arquivos `VOCAB_BASE*` e `VOCAB_REMOVIDO*` com base na curadoria
    - alterar o arquivo `termos_comparacao_treino.txt` com termos importantes para acompanhar a evolu√ß√£o do modelo
    
 4) Opcional: arquivos de exclus√£o e de transforma√ß√£o de termos
    - arquivos no formato `VOCAB_TRADUTOR*.txt` com transforma√ß√µes, ngramas etc, e um ou mais arquivos .
    - arquivos no roamto `VOCAB_REMOVIDO*.txt' com termos que ser√£o exclu√≠dos do vocab final (a diferen√ßa entre o arquivo de transforma√ß√£o √© que trabalha com termos √∫nicos do vocab).

## Criando o vocab manualmente (opcional):
 Os arquivos necess√°rios para o treino que ser√£o usados para a tokeniza√ß√£o s√£o:
    - `meu_modelo\doc2vecfacil\VOCAB_BASE_*.txt`: arquivos com termos que ser√£o treinados 
 Opcionais:
    - `meu_modelo\doc2vecfacil\VOCAB_REMOVIDO*.txt`: arquivos com termos que ser√£o ignorados
    - `meu_modelo\doc2vecfacil\VOCAB_TRADUTOR*.txt`: arquivos com termos ou frases que ser√£o removidas ou transformadas
 - Pode-se criar os arquivos manualmente com os termos desejados, ou aproveitar os arquivos de outro treino. Ou Ajustar os arquivos criados automaticamente incluindo ou retirando termos.
 - Pode-se criar arquivos de transforma√ß√£o automaticamente usando o c√≥digo `util_tradutor_termos.py-pasta = meu_modelo`. Ele vai carregar os arquivos da pasta `textos_vocab` e utilizar o `Phrases` do gensim para sugerir bigramas, trigramas e quadrigramas que poderam ser analisados e incorporados a um arquivo de transforma√ß√£o como `meu_modelo\doc2vecfacil\VOCAB_TRADUTOR_NGRAMAS.txt` por exemplo. Caso queira saber mais sobre a cria√ß√£o de ngramas usando esse componente, veja aqui: [`nGramasFacil`](readme_ngramas.md)

## Conferindo o processamento dos textos
- Pode-se conferir os arquivos `.clr` criados nas pastas `textos*` pois eles s√£o o resultado do processamento dos textos originais com o `TokenizadorInteligente`.
- Nesse arquivo √© poss√≠vel identificar os fragmentos e os tokens principais e verificar se a tokeniza√ß√£o est√° de acordo com o esperado. O treinamento do modelo ser√° feito com esse arquivo. 
- No in√≠cio do treinamento os arquivos `.clr` ser√£o atualizados para garantir que novos termos inclu√≠dos ou alterados manualmente sejam refletidos na tokeniza√ß√£o.
- Os arquivos `.clr` s√£o necess√°rios durante todo o treinamento e ser√£o recriados se n√£o forem encontrados, isso acelera o treinamento para n√£o haver necessidade de reprocessar o texto cada vez que o treinamento passar por ele.

## Passo a passo para treinar o modelo doc2vec: 
 Com os arquivos de vocab prontos, criados automaticamente ou manualmente, pode-se treinar o modelo.
 1) Conferir a pasta de texto e arquivos do vocab (o case dos nomes n√£o importa, caixa alta √© para facilitar a identifica√ß√£o):
    - `meu_modelo\textos_treino\`: colocar os arquivos que ser√£o usados no treinamento
    - `meu_modelo\doc2vecfacil\VOCAB_BASE*.txt`: arquivos com termos que ser√£o treinados 
    - `meu_modelo\doc2vecfacil\VOCAB_REMOVIDO*.txt`: arquivos com termos que ser√£o ignorados
    - `meu_modelo\doc2vecfacil\VOCAB_TRADUTOR*.txt`: arquivos com termos que ser√£o ignorados
 2) Rodar: `python util_doc2vec_facil.py -pasta ./meu_modelo`.
    - se j√° existir o modelo, o treinamento ser√° continuado.
    - sugere-se aguardar no m√≠nimo 1000 √©pocas, se poss√≠vel umas 5000
    - pode-se acompanhar a evolu√ß√£o do modelo criando ou alterando o arquivo `termos_comparacao_treino.txt` que cont√©m uma lista de termos para gera√ß√£o do arquivo `termos_comparacao.log` onde para cada termo ser√° apresentada uma lista de termos mais semelhantes, permitindo uma avalia√ß√£o do modelo em treinamento. Esse arquivo n√£o interfere no treino e pode ser modificado a qualquer momento.

## Par√¢metros
 - `python util_doc2vec_facil.py`
    - `-pasta` - nome da pasta de treinamento que cont√©m a pasta do modelo e as pastas de textos, o padr√£o √© `meu_modelo` se n√£o for informada.
    - `-treinar`' - iniciar o treinamento do modelo
    - `-reiniciar sim` - remove o modeo atual, se existir, e inicia um novo treinamento
    - `-testar` - carrega o modelo atual, se existir, e atualiza o arquivo `comparar_termos.log` com os termos encontrados no arquivo `termos_comparacao_treino.txt`
    - `-epocas` - define o n√∫mero de √©pocas que ser√£o treinadas, o padr√£o √© 5000 e pode ser interrompido ou acrescido a qualquer momento.
    - `-dimensoes` - define o n√∫mero de dimens√µes dos vetores de treinamento (n√£o pode ser alterado depois de iniciado o treinamento).
    - `-workers` - n√∫mero de threads de treinamento, padr√£o 100

 - `python util_doc2vec_vocab_facil.py`
    - `-pasta` - nome da pasta de treinamento que cont√©m as pastas de textos, o padr√£o √© `meu_modelo` se n√£o for informada.
    - `-reiniciar` - remove os arquivos de vocab autom√°ticos, se existirem, e reinicia a cria√ß√£o deles.
    - `-teste` - carrega o `TokenizadorInteligente` para verificar se os arquivos que ser√£o usados para o processamento no treino est√£o ok.

## Dicas:
 Ao rodar o c√≥digo para criar o vocab:
 - caso exista um ou mais arquivos do dicion√°rio principal e n√£o existam arquivos do secund√°rio, ser√° criado apenas o dicion√°rio secund√°rio com base nos textos complementares das pastas `textos_vocab_complementar`. Isso facilita criar novos modelos mantendo um dicion√°rio base padr√£o.
 - caso existam todos os dicion√°rios, ser√° criado/atualizado o arquivo de curadoria, sem modificar os dicion√°rios existentes. Usando o par√¢metros `-reiniciar`, o vocab autom√°tico e autom√°tico complementar ser√£o recriados.
 - se durante a prepara√ß√£o do dicion√°rio existirem documetnos na pasta `textos_treino`, o arquivo de curadoria ser√° criado usando os textos de treinamento, facilitando identificar os termos que n√£o ser√£o treinados, bem como outros atributos de todos os termos. Como o processo pode demorar, para um corpus muito grande pode-se deixar apenas alguns textos na pasta treino para a cria√ß√£o do vocab e colocar todos no momento de treinamento propriamente dito.
 - no arquivo de curadoria, a coluna `VOCAB` S/N indica se o termo est√° contido inteiro no vocab e a coluna `VOCAB_QUEBRADOS` S/N indica se o termo foi inclu√≠do ap√≥s ser fragmentado. Caso as duas colunas sejam N, isso indica que o termo n√£o ser√° treinado, nem inteiro e nem o seu formato `stemmer`+`#sufixo`.

### Termos comparados para acompanhar a evolu√ß√£o do modelo:
- Exemplo de sa√≠da do arquivo `comparar_termos.log` atualizado a cada √©poca.
- Esse log √© gerado com os termos ou frases dispon√≠veis no arquivo `termos_comparacao_treino.txt` que √© carregado no in√≠cio do treino e pode ser alterado sempre que desejado.
  - o arquivo cont√©m termos linha a linha e frases que podem ser comparadas.
Exemplo do arquivo `termos_comparacao_treino.txt`:
```
apresentada para o r√©u a decis√£o sobre o processo = apresentada para o acusado a senten√ßa sobre o processo
artigo
cobrados
cogitar 
compromisso
comprovadas
entendimento
lei
entorpecentes
julga
parcelas
termo
```
> üí° Nota: na primeira linha temos duas frases que ser√£o comparadas ao longo do treino. Nas outras linhas temos termos soltos que ser√£o apresentados os termos mais parecidos durante o treino. 
> O resultado do arquivo `comparar_termos.log` √© esse:
```
apresentada para o r√©u a decis√£o sobre o processo | apresentada para o acusado a senten√ßa sobre o processo (65%)
artigo               |  art (77%)                |  artigos (55%)            |  arts (53%)              
cobrados             |  pagos (54%)             
cogitar              |  falar (52%)             
compromisso          |  promessa (57%)          
comprovadas          |  demonstradas (58%)      
entendimento         |  posicionamento (52%)    
lei                  |  lei_federal (75%)        |  lei_complementar (72%)   |  cpp (63%) 
entorpecentes        |  drogas (64%)            
julga                |  julgou (71%)             |  julgando (53%)          
parcelas             |  prestacoes (60%)         |  despesas (55%)           |  quantias (52%)          
termo                |  peticao (64%)            |  inepcia (63%)           
```

## Usando o modelo:
 O modelo pode ser carregado facilmente:
 ```python 
 from util_doc2vec_facil import UtilDoc2VecFacil
 dv = UtilDoc2VecFacil(pasta_modelo=PASTA_MODELO)

frase1 = 'EXECU√á√ÉO POR T√çTULO EXTRAJUDICIAL DE HONOR√ÅRIO ADVOCAT√çCIO EMBARGOS ADJUDICA√á√ÉO PENHORAS'
frase2 = 'EMENTA SEGUROs de VIDA COBRAN√áA CUMULADA C PRETENS√ÉO INDENIZAT√ìRIA PRESCRI√á√ÉO RECONHECIDA'
frase3 = 'DE HONOR√ÅRIOS ADVOCAT√çCIOS EMBARGOS ADJUDICA√á√ÉO PENHORA EXECU√á√ÉO POR T√çTULO EXTRAJUDICIAL '
print('Frase1: ', frase1, '\nFrase2: ', frase2, '\n\t - Similaridade: ', dv.similaridade(frase1,frase2))
print('Frase1: ', frase1, '\nFrase3: ', frase3, '\n\t - Similaridade: ', dv.similaridade(frase1,frase3))        
print('\nTokens frase 1: ', dv.tokens_sentenca(frase1))
 ```
 
 <b>Resultado:</b>
 ```
Frase1:  EXECU√á√ÉO POR T√çTULO EXTRAJUDICIAL DE HONOR√ÅRIO ADVOCAT√çCIO EMBARGOS ADJUDICA√á√ÉO PENHORAS
Frase2:  EMENTA SEGUROs de VIDA COBRAN√áA CUMULADA C PRETENS√ÉO INDENIZAT√ìRIA PRESCRI√á√ÉO RECONHECIDA
         - Similaridade:  0.43190062046051025
Frase1:  EXECU√á√ÉO POR T√çTULO EXTRAJUDICIAL DE HONOR√ÅRIO ADVOCAT√çCIO EMBARGOS ADJUDICA√á√ÉO PENHORAS
Frase3:  DE HONOR√ÅRIOS ADVOCAT√çCIOS EMBARGOS ADJUDICA√á√ÉO PENHORA EXECU√á√ÉO POR T√çTULO EXTRAJUDICIAL
         - Similaridade:  0.46588313579559326

Tokens frase 1:  ['execucao', 'por', 'titulo', 'extrajudicial', 'de', 'honorario', 'advocaticio', 'embargos', 'adjudicacao', 'penhoras'] 
 ```
 
- O que precisa ser disponibilizado para o modelo funcionar:
  - `VOCAB_BASE*.txt` - arquivo com termos e fragmentos que comp√µem o vocab
  - `VOCAB_TRADUTOR*.txt` - arquivo de transforma√ß√µes do tokenizados
  - `VOCAB_REMOVER*.txt` - arquivo de exclus√µes do tokenizados
  - `doc2vec*` - arquivos do modelo treinado

## Dicas de uso:
- gravar os vetores, textos e metadados dos documentos no ElasticSearch
- fazer pesquisas com More Like This, vetoriais e por proximidade de termos como disponibilizado no componente [PesquisaElasticFacil](https://github.com/luizanisio/PesquisaElasticFacil) em breve.

