# Doc2VecFacil
Componente python que simplifica o processo de cria√ß√£o de um modelo `Doc2Vec` [`Gensim 4.0.1`](https://radimrehurek.com/gensim/models/doc2vec.html) com facilitadores para gera√ß√£o de um vocab personalizado e com a gera√ß√£o de arquivos de curadoria. Dicas de agrupamento de documentos similares, uso de `ElasticSearch` e `SingleStore`.
- se voc√™ n√£o sabe o que √© um modelo de similaridade, em resumo √© um algoritmo n√£o supervisionado para criar um modelo que transforma frases ou documentos em vetores matem√°ticos que podem ser comparados retornando um valor equivalente √† similaridade sem√¢ntica de documentos do mesmo contexto/dom√≠nio dos documentos usados no treinamento do modelo (doc2vec). Nesse cen√°rio a m√°quina 'aprende' o vocabul√°rio treinado e o contexto em que as palavras aparecem (word2vec), permitindo identificar a similaridade entre os termos, as frases e os documentos. O doc2vec amplia o treinamento do word2vec para frases ou documentos.
- alguns links para saber mais:
  - [`Paragraph Vector 2014`](https://cs.stanford.edu/~quocle/paragraph_vector.pdf) - a origem do Doc2Vec
  - [`Gensim 4.0.1 Doc2Vec`](https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html) - documenta√ß√£o do framework
  - [`me Amilar 2018`](https://repositorio.idp.edu.br/handle/123456789/2635) - Disserta√ß√£o de Mestrado IDP - Doc2Vec em documentos jur√≠dicos
  - [`Representa√ß√£o Sem√¢ntica Vetorial`](https://sol.sbc.org.br/index.php/erigo/article/view/7125) - Artigo UFG
  - [`Word2Vec Explained`](https://www.youtube.com/watch?v=yFFp9RYpOb0) - v√≠deo no Youtube
  - [`Word Embedding Explained and Visualized`](https://www.youtube.com/watch?v=D-ekE-Wlcds) - v√≠deo no Youtube
  - [`ti-exame`](https://www.ti-enxame.com/pt/python/como-calcular-similaridade-de-sentenca-usando-o-modelo-word2vec-de-gensim-com-python/1045257495/) - Word2Vec
  - [`Tomas Mikolov paper`](https://arxiv.org/pdf/1301.3781.pdf) - mais um artigo sobre o Doc2Vec

- Com essa compara√ß√£o vetorial, √© poss√≠vel encontrar documentos semelhantes a um indicado ou [`agrupar documentos semelhantes`](./docs/agrupamento.md) entre si de uma lista de documentos. Pode-se armazenar os vetores no `SingleStore` ou `ElasticSearch` para permitir uma pesquisa vetorial r√°pida e combinada com metadados dos documentos, como nas dicas [aqui](#dicas).

- O uso da similaridade permite tamb√©m um sistema sugerir r√≥tulos para documentos novos muito similares a documentos rotulados previamente ‚Äì como uma classifica√ß√£o r√°pida, desde que o r√≥tulo esteja relacionado ao conte√∫do geral do documento e n√£o a informa√ß√µes externas a ele. Rotula√ß√£o por informa√ß√µes muito espec√≠ficas do documento pode n√£o funcionar muito bem, pois detalhes do documento podem n√£o ser ressaltados na similaridade sem√¢ntica. Outra possibilidade seria o sistema sugerir revis√£o de rotula√ß√£o/classifica√ß√£o quando dois documentos possuem similaridades muito altas, mas r√≥tulos distintos, ou r√≥tulos iguais para similaridades muito baixas (n√£o √© necessariamente um erro, mas sugere-se confer√™ncia nesses casos). Ou o sistema pode auxiliar o usu√°rio a identificar r√≥tulos que precisam ser revistos, quando r√≥tulos diferentes s√£o encontrados para documentos muito semelhantes e os r√≥tulos poderiam ser unidos em um √∫nico r√≥tulo, por exemplo. Essas s√£o apenas algumas das possibilidades de uso da similaridade. 

- Em um recorte do espa√ßo vetorial criado pelo treinamento do modelo, pode-se perceber que documentos semelhantes ficam pr√≥ximos enquanto documentos diferentes ficam distantes entre si. Ent√£o agrupar ou buscar documentos semelhantes √© uma quest√£o de identificar a dist√¢ncia vetorial dos documentos ap√≥s o treinamento. Armazenando os vetores dos documentos no `ElasticSearch` ou `SingleStore`, essa tarefa √© simplificada, permitindo construir sistemas de busca sem√¢ntica com um esfor√ßo pequeno. Uma t√©cnica parecida pode ser usada para treinar e armazenar vetores de imagens para encontrar imagens semelhantes, mas isso fica para outro projeto.

![exemplo recorte espa√ßo vetorial](./exemplos/img_recorte_espaco_vetorial.png?raw=true "Exemplo recorte de espa√ßo vetorial")

> :bulb: Uma dica para conjuntos de documentos com pouca atualiza√ß√£o, √© fazer o c√°lculo da similaridade dos documentos e armazenar em um banco transacional qualquer para busca simples pelos metadados da similaridade. Por exemplo uma tabela com as colunas `seq_doc_1`, `seq_doc_2` e `sim` para todos os documentos que possuam similaridade acima de nn% a ser avaliado de acordo com o projeto. Depois basta fazer uma consulta simples para indicar documentos similares ao que o usu√°rio est√° acessando, por exemplo.

- O core desse componente √© o uso de um Tokenizador Inteligente que usa as configura√ß√µes dos arquivos contidos na pasta do modelo para tokenizar os arquivos de treinamento e os arquivos novos para compara√ß√£o no futuro (toda a configura√ß√£o do tokenizador √© opcional).
- Esse √© um reposit√≥rio de estudos. Analise, ajuste, corrija e use os c√≥digos como desejar.
> :thumbsup: <sub> Agradecimentos especiais ao Miguel Angelo Neto do Paran√° por v√°rios feedbacks contribuindo para a corre√ß√£o de bugs e a melhoria da documenta√ß√£o.</sub><br>

> :warning: <sub>A quantidade de termos treinados e de √©pocas de treinamento s√£o valores que dependem do objetivo e do tipo de texto de cada projeto. Quanto mais termos, mais detalhes e mais diferen√ßas ser√£o destacadas entre os textos e o modelo vai real√ßar as particularidades da escrita. Escolhendo menos termos mais relacionados com o dom√≠nio analisado, e compondo ngramas, h√° uma chance maior do modelo real√ßar a tem√°tica geral dos textos.</sub>

### As etapas de um treinamento s√£o simples:
1) reservar um volume de documentos que represente a sem√¢ntica que ser√° treinada. Ent√£o o primeiro passo √© extrair e separar em uma pasta os documentos que ser√£o usados no treinamento. √â interessante que sejam documentos ‚Äútexto puro‚Äù (n√£o ocerizados), mas n√£o impede que sejam usados documentos ocerizados na falta de documentos ‚Äútexto puro‚Äù. Com textos com muito ru√≠do, como em textos ocerizados, torna-se mais importante a curadoria de termos como ser√° descrito mais abaixo.
2) preparar o ambiente python caso ainda n√£o tenha feito isso: [`anaconda`](https://www.anaconda.com/) + [`requirements`](./src/requirements.txt)
3) baixar os arquivos do [`projeto`](./src/) 
4) baixar um [`modelo`](./exemplos/) ou criar a sua estrutura de pastas
5) rodar o treinamento, a curadoria, o agrupamento e explorar os recursos que o uso do espa√ßo vetorial permite
> :bulb: <sub> Nota: Esse √© o [tutorial oficial](https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#introducing-paragraph-vector), a ideia do componetne √© simplificar a gera√ß√£o e uso do modelo treinado, mas n√£o h√° nada muito especial se comparado aos c√≥digos da documenta√ß√£o. </sub>

<hr>

## Esse componente `Doc2VecFacil` trabalha em duas etapas:
 - cria√ß√£o/configura√ß√£o e curadoria de um [vocab](#vocab) personalizado para o [`TokenizadorInteligente`](./docs/vocab_e_tokenizador.md).
   - `python util_doc2vec_vocab_facil.py -pasta ./meu_modelo`
 - treinamento do modelo usando a estrutura de tokeniza√ß√£o criada 
   - `python util_doc2vec_facil.py -pasta ./meu_modelo -treinar`
> üí° <sub>Nota: para interromper o treino sem correr o risco corromper o modelo durante a grava√ß√£o, basta criar um arquivo `meu_modelo/doc2vecfacil/parar.txt` na pasta do modelo que o treinamento ser√° interrompido ao final da itera√ß√£o em andamento.</sub>

 - Aqui tem um [`passo a passo simplificado`](./docs/passo_a_passo_facil.md) para alguns cen√°rios de treinamento com a estrutura de pastas e arquivos, bem como [`exemplos`](./exemplos) de configura√ß√µes de treinamento.
 - Alguns dos cen√°rios do passo a passo:
   - [Treino simples sem prepara√ß√£o de vocab](./docs/passo_a_passo_facil.md#1-quero-treinar-sem-preparar-um-vocab)
   - [Treino com ngramas](./docs/passo_a_passo_facil.md#3-quero-criar-ngramas-ou-limpar-o-texto-com-termos-que-n%C3%A3o-devem-ser-treinados)
   - [Treino com curadoria de termos](./docs/passo_a_passo_facil.md#4-quero-criar-meu-vocab-do-zero-fazer-curadoria-e-depois-treinar)
 
 - Logo abaixo est√£o as explica√ß√µes detalhadas de como funciona o componente e como usar o seu modelo treinado para pesquisas de documentos semelhantes semanticamente (por vetores) e/ou textualmente (por termos), como realizar agrupamento de documentos por similaridade para auxiliar na organiza√ß√£o de documentos usando o `ElasticSearch` ou o `SingleStore` com a pesquisa vetorial.

- :page_with_curl: <b>C√≥digos</b>: 
  - [`Cria√ß√£o de vocab`](./src/util_doc2vec_vocab_facil.py)
  - [`UtilDoc2VecFacil`](./src/util_doc2vec_facil.py) e [`UtilDoc2VecFacil_Treinamento`](./src/util_doc2vec_facil.py) 
  - [`TradutorTermos`](./src/util_tradutor_termos.py)
  - [`Cria√ß√£o de ngramas`](./src/util_ngramas_facil.py) dicas aqui -> [NGramasFacil](./docs/readme_ngramas.md)
  - [`UtilAgrupamentoFacil`](./src/util_agrupamento_facil.py) dicas aqui -> [agrupamento](./docs/agrupamento.md)
  - [`Quebra de par√°grafos`](./src/util_quebrar_paragrafos.py) dicas aqui -> [par√°grafos para treinamento](./docs/quebrar_paragrafos.md)

`EM BREVE`: Ser√° disponibilizado um servi√ßo exemplo em conjunto com o componente [PesquisaElasticFacil](https://github.com/luizanisio/PesquisaElasticFacil) para cria√ß√£o de modelos de similaridade textual, agregando valor √†s pesquisas do ElasticSearch de forma simples com um modelo treinado no corpus espec√≠fico de cada projeto.

## Cria√ß√£o do vocab personalizado <a name="vocab">

O arquivo `util_doc2vec_vocab_facil.py` √© complementar √† classe `Doc2VecFacil` e serve para facilitar a cria√ß√£o de arquivos que configuram o `TokenizadorInteligente`. A ideia √© trabalhar com termos importantes para o modelo, adicionados a termos complementares compostos por fragmentos de termos `stemmer` + `sufixo`. Com isso novos documentos que possuam termos fora do vocab principal podem ter o stemmer e o sufixo dentro do vocab do modelo, criando um vocab mais flex√≠vel e menor. √â poss√≠vel tamb√©m transformar termos ou conjunto de termos durante o processamento, como criar n-gramas, reduzir nomes de organiza√ß√µes em sigla, remover termos simples ou compostos etc.
- veja como funciona o [`TokenizadorInteligente`](./docs/vocab_e_tokenizador.md) e como analisar e interferir no treinamento ajustando os termos dos arquivos de configura√ß√£o.

## Conferindo o processamento dos textos
- Durante o treinamento s√£o criados arquivos com a extens√£o `.clr` para cada arquivo `.txt` da pasta `texto_treino`, eles s√£o o resultado do processamento dos textos originais com o `TokenizadorInteligente`.
- Nesses arquivos √© poss√≠vel identificar os fragmentos, os tokens principais e os termos compostos, e verificar se a tokeniza√ß√£o est√° de acordo com o esperado. O treinamento do modelo ser√° feito com esse arquivo e o vocab de treinamento √© o resultado da an√°lise desses termos. O objetivo do `TokenizadorInteligente` √© preparar o texto que ser√° treinado e fazer o mesmo processo em textos novos para vetoriza√ß√£o usando o modelo no futuro. 
- No in√≠cio do treinamento os arquivos `.clr` ser√£o atualizados para garantir que novos termos inclu√≠dos ou alterados manualmente sejam refletidos na tokeniza√ß√£o.
- Os arquivos `.clr` s√£o necess√°rios durante todo o treinamento e ser√£o recriados se n√£o forem encontrados, isso acelera o treinamento para n√£o haver necessidade de reprocessar os textos cada vez que o treinamento passar por eles.

## Treinando o modelo doc2vec: 
 Com os arquivos de vocab prontos, criados automaticamente ou manualmente, pode-se treinar o modelo.<br>
 Siga os passos do cen√°rio que atende √† sua necessidade: [`passo a passo`](./docs/passo_a_passo_facil.md)

### Par√¢metros
 - `python util_doc2vec_facil.py`
    - `-pasta` - nome da pasta de treinamento que cont√©m a pasta do modelo e as pastas de textos, o padr√£o √© `meu_modelo` se n√£o for informada.
    - `-treinar`' - iniciar o treinamento do modelo
    - `-reiniciar sim` - remove o modeo atual, se existir, e inicia um novo treinamento (o sim √© para garantir que se quer apagar o modelo e reiniciar). Pode-se tamb√©m apagar manualmente os arquivos `doc2vec.*` para reiniciar o modelo.
    - `-testar` - carrega o modelo atual, se existir, e apresenta no console a compara√ß√£o de termos encontrados no arquivo `termos_comparacao_treino.txt` e o agrupamento de textos da pasta `textos_teste`.
    - `-epocas` - define o n√∫mero de √©pocas que ser√£o treinadas, o padr√£o √© 5000 e pode ser interrompido ou acrescido a qualquer momento.
    - `-dimensoes` - define o n√∫mero de dimens√µes dos vetores de treinamento (n√£o pode ser alterado depois de iniciado o treinamento). N√£o sabe como escolher use o padr√£o 300.
    - `-workers` - n√∫mero de threads de treinamento, padr√£o 100
    - `-bloco` - n√∫mero de treinos realizados para cada grava√ß√£o e testes do modelo - padr√£o 5

 - `python util_doc2vec_vocab_facil.py`
    - `-pasta` - nome da pasta de treinamento que cont√©m as pastas de textos, o padr√£o √© `meu_modelo` se n√£o for informada.
    - `-treino` - cria a planilha de curadoria com a pasta `textos_treino`, sem esse par√¢mtro a planilha √© criada com a pasta `textos_vocab`.
    - `-teste` - cria a planilha de curadoria com a pasta `textos_teste`, sem esse par√¢mtro a planilha √© criada com a pasta `textos_vocab`.
  > :bulb: <sub>Nota: s√£o muitas op√ß√µes de uso da curadoria para cria√ß√£o de um bom vocab. Se n√£o sabe por onde come√ßar, copie todos os termos listados na planilha para um arquivo `VOCAB_BASE.txt` e crie um arquivo `VOCAB_REMOVIDO.txt` com stopwords.</sub><br>
  <sub>Caso os seus documentos sejam limpos (n√£o sejam ocerizados), preocupe-se inicialmente apenas com o arquivo `VOCAB_REMOVIDO.txt` para um treino mais simples sem prefixos e sufixos treinando todo o vocabul√°rio e removendo apenas stopwords.</sub>
  
### Termos comparados para acompanhar a evolu√ß√£o do modelo:
- Exemplo de sa√≠da do arquivo `comparar_termos.log` atualizado a cada √©poca.
- Esse log √© gerado com os termos ou frases dispon√≠veis no arquivo `termos_comparacao_treino.txt` que √© carregado no in√≠cio do treino e pode ser alterado sempre que desejado.
  - o arquivo cont√©m termos linha a linha e frases que podem ser comparadas.
Exemplo do arquivo `termos_comparacao_treino.txt`:
```
apresentada para o r√©u a decis√£o sobre o processo = apresentada para o acusado a senten√ßa sobre o processo
artigo
cobrados
cogitar 
compromisso
comprovadas
entendimento
lei
entorpecentes
julga
parcelas
termo
```
> üí° <sub>Nota: na primeira linha temos duas frases que ser√£o comparadas ao longo do treino. Nas outras linhas temos termos soltos que ser√£o apresentados os termos mais parecidos durante o treino. Coloque quantos termos ou frases desejar. Aparecer√£o os termos que tiverem similares com mais de 50% de similaridade.</sub><br>
  > <sub>O resultado do arquivo `comparar_termos.log` √© esse:</sub>
```
apresentada para o r√©u a decis√£o sobre o processo | apresentada para o acusado a senten√ßa sobre o processo (65%)
artigo               |  art (77%)                |  artigos (55%)            |  arts (53%)              
cobrados             |  pagos (54%)             
cogitar              |  falar (52%)             
compromisso          |  promessa (57%)          
comprovadas          |  demonstradas (58%)      
entendimento         |  posicionamento (52%)    
lei                  |  lei_federal (75%)        |  lei_complementar (72%)   |  cpp (63%) 
entorpecentes        |  drogas (64%)            
julga                |  julgou (71%)             |  julgando (53%)          
parcelas             |  prestacoes (60%)         |  despesas (55%)           |  quantias (52%)          
termo                |  peticao (64%)            |  inepcia (63%)           
```

### Arquivos comparados para acompanhar a evolu√ß√£o do modelo:
- Semelhante a compara√ß√£o de termos, pode-se criar uma pasta `textos_teste` com alguns arquivos para compara√ß√£o durante o treinamento. 
- Uma sugest√£o de avalia√ß√£o do modelo √© colocar arquivos com indicadores de grupos para avaliar pelos nomes se est√£o sendo agrupados como esperado.
- Por exemplo, colocando no nome do arquivo `grupo1`, `grupo2` etc, pode-se avaliar se os arquivos est√£o sendo agrupados por similaridade da forma que √© desejado. Com isso pode-se ajustar os par√¢metros do modelo para avaliar se est√° se aproximando mais ou menos do que se espera. 
- O resultado de compara√ß√£o ser√° colocado no arquivo `comparar_arquivos.log` como no exemplo abaixo.
- Um dos arquivos √© escolhido para ser comparado com ele mesmo para ter mais uma informa√ß√£o para avalia√ß√£o do modelo. Como informado na documenta√ß√£o do Doc2Vec, chamadas subsequentes de um mesmo conte√∫do podem inferir vetores diferentes. Essa diferen√ßa diminui aumentando o n√∫mero de √©pocas na infer√™ncia do vetor. 
- Como a compara√ß√£o de arquivos pode exigir mais processamento, ela aguarda pelo menos 5 minutos para ser atualizada. Se o arquivo for exclu√≠do, ela ser√° realizada ap√≥s o final da pr√≥xima √©poca. A compara√ß√£o de arquivos tamb√©m ser√° realizada ao usar o par√¢metro `-testar` para testar o modelo.
![exemplo arquivo comparar_arquivos.log](./exemplos/img_comparar_arquivos.png?raw=true "comparar arquivos.log")
> :bulb: <sub>Nota: Essa rotula√ß√£o n√£o faz o treinamento ser supervisionado, apenas auxilia a avalia√ß√£o do modelo, j√° que os r√≥tulos n√£o s√£o levados em considera√ß√£o no treinamento.</sub><br>
  > <sub>No [`passo a passo`](./docs/passo_a_passo_facil.md) tem dicas de como rotular os documentos para que o treinamento busque aproximar os vetores dos documentos com mesmos r√≥tulos.</sub>  

## Usando o modelo:
O que precisa ser disponibilizado para o modelo funcionar:<br>
 :file_folder: `modelo_teste` <br>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - `VOCAB_BASE*.txt` - arquivo com termos e fragmentos que comp√µem o vocab <br>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - `VOCAB_TRADUTOR*.txt` - arquivo de transforma√ß√µes do tokenizados <br>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - `VOCAB_REMOVER*.txt` - arquivo de exclus√µes do tokenizados (stopwords por exemplo) <br>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - `doc2vec*` - arquivos do modelo treinado <br>
 
 Coloque tudo em uma pasta com o nome que desejar e pronto. Esse √© um pacote do seu modelo. <br>

O modelo pode ser carregado facilmente:
 ```python 
 from util_doc2vec_facil import UtilDoc2VecFacil
 dv = UtilDoc2VecFacil(pasta_modelo=PASTA_MODELO)

frase1 = 'EXECU√á√ÉO POR T√çTULO EXTRAJUDICIAL DE HONOR√ÅRIO ADVOCAT√çCIO EMBARGOS ADJUDICA√á√ÉO PENHORAS'
frase2 = 'EMENTA SEGUROs de VIDA COBRAN√áA CUMULADA C PRETENS√ÉO INDENIZAT√ìRIA PRESCRI√á√ÉO RECONHECIDA'
frase3 = 'DE HONOR√ÅRIOS ADVOCAT√çCIOS EMBARGOS ADJUDICA√á√ÉO PENHORA EXECU√á√ÉO POR T√çTULO EXTRAJUDICIAL '
print('Frase1: ', frase1, '\nFrase2: ', frase2, '\n\t - Similaridade: ', dv.similaridade(frase1,frase2))
print('Frase1: ', frase1, '\nFrase3: ', frase3, '\n\t - Similaridade: ', dv.similaridade(frase1,frase3))        
print('\nTokens frase 1: ', dv.tokens_sentenca(frase1))
print('\nVetor frase 1: ', dv.vetor_sentenca(frase1, normalizado = True, epocas = 3):  
 ```
 
 <b>Resultado:</b>
 ```
Frase1:  EXECU√á√ÉO POR T√çTULO EXTRAJUDICIAL DE HONOR√ÅRIO ADVOCAT√çCIO EMBARGOS ADJUDICA√á√ÉO PENHORAS
Frase2:  EMENTA SEGUROs de VIDA COBRAN√áA CUMULADA C PRETENS√ÉO INDENIZAT√ìRIA PRESCRI√á√ÉO RECONHECIDA
         - Similaridade:  0.43190062046051025
Frase1:  EXECU√á√ÉO POR T√çTULO EXTRAJUDICIAL DE HONOR√ÅRIO ADVOCAT√çCIO EMBARGOS ADJUDICA√á√ÉO PENHORAS
Frase3:  DE HONOR√ÅRIOS ADVOCAT√çCIOS EMBARGOS ADJUDICA√á√ÉO PENHORA EXECU√á√ÉO POR T√çTULO EXTRAJUDICIAL
         - Similaridade:  0.46588313579559326

Tokens frase 1:  ['execucao', 'por', 'titulo', 'extrajudicial', 'de', 'honorario', 'advocaticio', 'embargos', 'adjudicacao', 'penhoras'] 
Vetor frase 1: [-0.09982843697071075, 0.05516746640205383, 0.09597551822662354, -0.03438882157206535, ...]
 ```
 
## Dicas de uso: <a name="dicas">
- gravar os vetores, textos e metadados dos documentos no [`ElasticSearch`](https://www.elastic.co/pt/), e usar os recursos de pesquisas: More Like This, vetoriais e por proximidade de termos como disponibilizado no componente [`PesquisaElasticFacil`](https://github.com/luizanisio/PesquisaElasticFacil) ou criar sua pr√≥pria estrutura de dados com [`essas dicas`](https://github.com/luizanisio/PesquisaElasticFacil/blob/main/docs/ElasticQueries.md).
- gravar os vetores, textos e metadados no [`SingleStore`](https://www.singlestore.com/) e criar views de similaridade para consulta em tempo real dos documentos inseridos na base, incluindo filtros de metadados e textuais como nos exemplos dispon√≠veis aqui: [`dicas SingleStore`](./docs/readme_dicas.md).
