# Doc2VecFacil

Componente python que simplifica o processo de cria√ß√£o de um modelo `Doc2Vec` [`Gensim 4.0.1`](https://radimrehurek.com/gensim/) com facilitadores para gera√ß√£o de um vocab personalizado e com a gera√ß√£o de arquivos de curadoria.
- se voc√™ n√£o sabe o que √© um modelo de similaridade, em resumo √© um algoritmo n√£o supervisionado para transformar frases ou documentos em vetores matem√°ticos que podem ser comparados retornando um valor que representa a similaridade sem√¢ntica entre dois ou mais documentos. Nesse contexto a m√°quina 'aprende' o vocabul√°rio treinado e o contexto em que as palavras aparecem, permitindo identificar a similaridade entre os termos, as frases e os documentos.
- Com essa compara√ß√£o vetorial, √© poss√≠vel encontrar documentos semelhantes a um indicado, agrupar documentos semelhantes de uma lista de documentos e monitorar documentos que entram na base ao compar√°-los com os documentos marcados como importantes para monitoramento. 
- Esse √© um reposit√≥rio de estudos, analise, ajuste, corrija e use os c√≥digos como desejar.
- O core desse componente √© o uso de um Tokenizador Inteligente que usa as configura√ß√µes dos arquivos contidos na pasta do modelo para tokenizar os arquivos de treinamento e os arquivos novos para compara√ß√£o no futuro.

### Esse componente `Doc2VecFacil` trabalha em duas etapas:
 - cria√ß√£o/configura√ß√£o de um vocab personalizado para o Tokenizador Inteligente.
   - `python util_doc2vec_vocab_facil.py -pasta ./meu_modelo`
 - treinamento do modelo usando a estrutura de tokeniza√ß√£o criada 
   - `python util_doc2vec_facil.py -pasta ./meu_modelo` -treinar

 - Aqui tem um passo a passo simplificado para cria√ß√£o/configura√ß√£o do vocab e realiza√ß√£o do treinamento: [`Passo a Passo`](passo_a_passo_facil.md)
 
 - Logo abaixo est√£o as explica√ß√µes detalhadas de como ele funciona e como usar o seu modelo para pesquisas de documentos semelhantes semanticamente (por vetores) e/ou textualmente (por termos), como realizar agrupamento de documentos por similaridade para auxiliar na organiza√ß√£o de documentos usando o ElasticSearch e a pesquisa vetorial.

- :page_with_curl: <b>C√≥digos</b>: 
  - [`Cria√ß√£o de vocab`](./src/util_doc2vec_vocab_facil.py)
  - [`UtilDoc2VecFacil`](./src/util_doc2vec_facil.py) e [`UtilDoc2VecFacil_Treinamento`](./src/util_doc2vec_facil.py) 
  - [`TradutorTermos`](./src/util_tradutor_termos.py)
  - [`Cria√ß√£o de ngramas`](./src/util_ngramas_facil.py) dicas aqui [NGramasFacil](readme_ngramas.md)

`EM BREVE`: Ser√° disponibilizado um servi√ßo exemplo em conjunto com o componente [PesquisaElasticFacil](https://github.com/luizanisio/PesquisaElasticFacil) para cria√ß√£o de modelos de similaridade textual, agregando valor √†s pesquisas do ElasticSearch de forma simples com um modelo treinado no corpus espec√≠fico de cada projeto.

## Cria√ß√£o do vocab personalizado

O arquivo `util_doc2vec_vocab_facil.py` √© complementar √† classe `Doc2VecFacil` e serve para facilitar a cria√ß√£o de arquivos que configuram o `TokenizadorInteligente`. A ideia √© trabalhar com termos importantes para o modelo, adicionados a termos complementares compostos por fragmentos de termos `stemmer` + `sufixo`. Com isso novos documentos que possuam termos fora do vocab principal podem ter o stemmer e o sufixo dentro do vocab do modelo, criando um vocab mais flex√≠vel e menor. √â poss√≠vel tamb√©m transformar termos ou conjunto de termos durante o processamento, como criar n-gramas, reduzir nomes de organiza√ß√µes em sigla, remover termos simples ou compostos etc.

## Como funciona o Tokenizador Inteligente
  - Ao ser instanciado, o tokenizador busca os termos do vocab de treinamento contidos nos arquivos com padr√£o `VOCAB_BASE*.txt` (n√£o importa o case).
  - Podem existir listas de termos que ser√£o exclu√≠dos do treinamento, basta esteram em arquivos com o padr√£o `VOCAB_REMOVIDO*.txt`.
  - Podem existir transformadores de termos nos arquivos com o padr√£o `VOCAB_TRADUTOR*.txt` que podem conter termos simples ou compostos que ser√£o convertidos em outros termos simples ou compostos, como ngramas por exempo. Veja [`NGramasFacil`](readme_ngramas.md) para mais detalhes.
  - Os tradutores funcionam ap√≥s a limpeza do texto e transformam termos de acordo com a configura√ß√£o no arquivo:
    - `termo1 => termo2` - converte o `termo1` em `termo2` quando encontrado no texto (ex. `min => ministro`)
    - `termo1 termo2 => termo1_termo2` - converte o termo composto `termo1 termo2` em um termo √∫nico `termo1_termo2` (Ex. `processo penal => processo_penal`)
    - `termo1 termo2` - remove o termo composto `termo1 termo2` (Ex. `documento digital => ` ou `documento digital`)
  - Os tradutores podem ser usados para converter nomes de organiza√ß√µes em suas siglas, termos compostos em um termo √∫nicos (ngramas) e at√© termos conhecidos como id√™nticos em sua forma mais usual. √â importante ressaltar que quanto maior o n√∫mero de termos para transforma√ß√£o, maior o tempo de processamento, mesmo usando recursos otimizados para essa transforma√ß√£o (veja a classe `TradutorTermos` no arquivo [`util_tradutor_termos.py`](./src/util_tradutor_termos.py) ). 
    - Est√° dispon√≠vel um gerador de bigramas e quadrigramas aqui [`NGramasFacil`](readme_ngramas.md) para gerar sugest√µes autom√°ticas de termos que podem ser unificados.

> üí° A ideia de criar v√°rios arquivos √© para organizar por dom√≠nios. Pode-se, por exemplo, criar um arquivo `VOCAB_BASE portugues.txt` com termos que far√£o parte de v√°rios modelos, um arquivo `VOCAB_BASE direito.txt` com termos do direito que ser√£o somados ao primeiro no treinamento, um arquivo `VOCAB_BASE direito fragmentos.txt` com fragmentos (`stemmer` + `sufixos`) de termos do direito, e assim por diante. Facilitando evolu√ß√µes futuras dos vocabul√°rios.

### Arquivo de curadoria para cria√ß√£o do vocab
 Ao rodar o c√≥digo `python util_doc2vec_vocab_facil.py -pasta ./meu_modelo`, ser√° criado um arquivo de curadoria de termos `curadoria_planilha_vocab.xlsx` com os termos encontrados nos textos da pasta `textos_vocab`. 
 - coloque na pasta `textos_vocab` textos que contenham boas palavras, limpas de prefer√™ncia. Podem ser listas retiradas de algum documento, n√£o importa o contexto delas, apenas as palavras nessa primeira etapa. Ent√£o listas de palavras e documentos como gram√°ticas e dicion√°rios de portugu√™s digitais parecem uma boa op√ß√£o. Coloque tamb√©m documentos com palavras relacionadas ao corpus desejado (psicologia, medicina, legisla√ß√£o, administra√ß√£o, etc). Esse site permite uma an√°lise muito boa de termos e suas caracter√≠sticas, bem como encontrar novos termos derivados de outros termos [`Dicio`](https://www.dicio.com.br/).
 - Alguns termos podem n√£o ser t√£o importantes para o dom√≠nio escolhido, mas podem ser importantes para o contexto. Esses termos podem compor o dicion√°rio em forma de `stemmer` + `sufixo`. Aos termos n√£o encontrados no dicion√°rio durante a tokeniza√ß√£o para treinamento, ser√° aplicado o stemmer com o sufixo ap√≥s o stemmer. Caso o stemmer esteja no vocab de treinamento, este ser√° usado. O sufixo √© opcional e ser√° inclu√≠do se estiver no vocab de treinamento tamb√©m.
 - Essa combina√ß√£o de termos completos e fragmentos (stemmer + sufixo) possibilita criar palavras por combina√ß√£o ao submeter um documento novo ao modelo que contenha termos fora do vocam de treinamento.
 - Opcionalmente pode-se usar o par√¢metro `-treino` para gerar o arquivo de curadoria com base nos arquivos da pasta `texto_treino`.
   
 - <b>Exemplo</b>: `engloba` pode ser composta por `englob` `#a`, e outras forma√ß√µes podem ocorrer como `englob` `#ada`, `englob` `#adamente`, `englob` `#adas` caso esses  fragmentos estejam dispon√≠veis no vocabul√°rio de treinamento.
   - O vocab de treinamento n√£o precisa do `#` antes do sufixo, apenas dos fragmentos. Mas durante o treinamento os fragmentos usados como sufixo iniciar√£o com `#` para facilitar sua identifica√ß√£o e diferenciar dos termos principais no modelo final.
 - <b>Exemplo de tokeniza√ß√£o com termos simples, compostor e fragmentos</b>: 
   ```
   ['atendiam_testemunha', 'seu', 'depoimento', 'apesar', 'de', 'trazer', 'algumas', 'impreciso', '#es', 'sobre', 'os', 'fatos', 'atend', '#o', 'se', 'os', 'jurados', 'as', 'provas', 'produzidas', 'em', 'plenari', '#os']
   ```

- Veja o [`passo a passo`](passo_a_passo_facil.md) para criar o vocabul√°rio de treinamento de acordo com o cen√°rio desejado e realizar o treinamento propriamente dito.

### Exemplo de arquivo `curadoria_planilha_vocab.xlsx` de curadoria de termos:
| TERMO                  | QUEBRADO         | TFIDF   | TAMANHO |  QTD  | QTD_DOCS | COMPOSTO | VOCAB | VOCAB_QUEBRADOS | ESTRANHO |
|------------------------|------------------|:-------:|:-------:|:-----:|:--------:|:--------:|:------|:---------------:|:--------:|
| acao_penal             |                  | 0,37127 |   	30	  |  178  |   	44	   |    S     |  	S   |        N        |    N     |
| adaptacao              | adaptaca o       | 0,30105 |    10   |   91  |    28    |    N     |   S   |        N        |    N     |
| advogado               | advog ado        | 0,49000 |    7    |  1736 |    810   |    N     |   S   |        N        |    N     |
| custas                 | cust as          | 0,41286 |    6    |  740  |    417   |    N     |   S   |        N        |    N     |
| materia_constitucional	|                  | 0,20749 |   	22	  |   8   |    	2	   |    S	    |   S   |       	N        |    N     |

> üí° Notas sobre as colunas: 
> - `TFIDF` - cont√©m o maior peso que o termo teve dentre os pesos que teve nos documentos - [Saiba mais sobre `TFIDF`](https://www.ti-enxame.com/pt/python/interpretar-um-resumo-das-pontuacoes-das-palavras-do-tf-idf-nos-documentos/829990829/)
> - `TAMANHO` - √© o tamanho do termo
> - `QTD` - √© a quantidade de vezes que o termo apareceu no corpus
> - `QTD_DOCS` - √© a quantidade de documentos onde o termo apareceu
> - `COMPOSTO` Sim / N√£o - indica se o termo √© composto 
> - `VOCAB` Sim / N√£o - indica se o termo est√° presente no vocab principal
> - `VOCAB_QUEBRADOS` Sim / N√£o - indica se pelo menos o stemmer do termo est√° presente no vocab principal
> - `ESTRANHO` Sim / N√£o - termos sem vogais ou com consoantes com v√°rias repeti√ß√µes

## Conferindo o processamento dos textos
- Pode-se conferir os arquivos `.clr` criados nas pastas `texto_treino` pois eles s√£o o resultado do processamento dos textos originais com o `TokenizadorInteligente`.
- Nesse arquivo √© poss√≠vel identificar os fragmentos, os tokens principais e os termos compostos, e verificar se a tokeniza√ß√£o est√° de acordo com o esperado. O treinamento do modelo ser√° feito com esse arquivo. 
- No in√≠cio do treinamento os arquivos `.clr` ser√£o atualizados para garantir que novos termos inclu√≠dos ou alterados manualmente sejam refletidos na tokeniza√ß√£o.
- Os arquivos `.clr` s√£o necess√°rios durante todo o treinamento e ser√£o recriados se n√£o forem encontrados, isso acelera o treinamento para n√£o haver necessidade de reprocessar o texto cada vez que o treinamento passar por ele.

## Treinando o modelo doc2vec: 
 Com os arquivos de vocab prontos, criados automaticamente ou manualmente, pode-se treinar o modelo.<br>
 Siga os passos do cen√°rio que atende √† sua necessidade: [`passo a passo`](passo_a_passo_facil.md)

### Par√¢metros
 - `python util_doc2vec_facil.py`
    - `-pasta` - nome da pasta de treinamento que cont√©m a pasta do modelo e as pastas de textos, o padr√£o √© `meu_modelo` se n√£o for informada.
    - `-treinar`' - iniciar o treinamento do modelo
    - `-reiniciar sim` - remove o modeo atual, se existir, e inicia um novo treinamento (o sim √© para garantir que se quer apagar o modelo e reiniciar)
    - `-testar` - carrega o modelo atual, se existir, e atualiza o arquivo `comparar_termos.log` com os termos encontrados no arquivo `termos_comparacao_treino.txt`
    - `-epocas` - define o n√∫mero de √©pocas que ser√£o treinadas, o padr√£o √© 5000 e pode ser interrompido ou acrescido a qualquer momento.
    - `-dimensoes` - define o n√∫mero de dimens√µes dos vetores de treinamento (n√£o pode ser alterado depois de iniciado o treinamento).
    - `-workers` - n√∫mero de threads de treinamento, padr√£o 100

 - `python util_doc2vec_vocab_facil.py`
    - `-pasta` - nome da pasta de treinamento que cont√©m as pastas de textos, o padr√£o √© `meu_modelo` se n√£o for informada.
    - `-treino` - cria a planilha de curadoria com a pasta `textos_treino`, sem esse par√¢mtro a planilha √© criada com a pasta `textos_vocab`.
    - `-teste` - carrega o `TokenizadorInteligente` para verificar se os arquivos que ser√£o usados para o processamento no treino est√£o ok.

### Termos comparados para acompanhar a evolu√ß√£o do modelo:
- Exemplo de sa√≠da do arquivo `comparar_termos.log` atualizado a cada √©poca.
- Esse log √© gerado com os termos ou frases dispon√≠veis no arquivo `termos_comparacao_treino.txt` que √© carregado no in√≠cio do treino e pode ser alterado sempre que desejado.
  - o arquivo cont√©m termos linha a linha e frases que podem ser comparadas.
Exemplo do arquivo `termos_comparacao_treino.txt`:
```
apresentada para o r√©u a decis√£o sobre o processo = apresentada para o acusado a senten√ßa sobre o processo
artigo
cobrados
cogitar 
compromisso
comprovadas
entendimento
lei
entorpecentes
julga
parcelas
termo
```
> üí° Nota: na primeira linha temos duas frases que ser√£o comparadas ao longo do treino. Nas outras linhas temos termos soltos que ser√£o apresentados os termos mais parecidos durante o treino. Coloque quantos termos ou frases desejar. Aparecer√£o os termos que tiverem similares com mais de 50% de similaridade.<br>
> O resultado do arquivo `comparar_termos.log` √© esse:
```
apresentada para o r√©u a decis√£o sobre o processo | apresentada para o acusado a senten√ßa sobre o processo (65%)
artigo               |  art (77%)                |  artigos (55%)            |  arts (53%)              
cobrados             |  pagos (54%)             
cogitar              |  falar (52%)             
compromisso          |  promessa (57%)          
comprovadas          |  demonstradas (58%)      
entendimento         |  posicionamento (52%)    
lei                  |  lei_federal (75%)        |  lei_complementar (72%)   |  cpp (63%) 
entorpecentes        |  drogas (64%)            
julga                |  julgou (71%)             |  julgando (53%)          
parcelas             |  prestacoes (60%)         |  despesas (55%)           |  quantias (52%)          
termo                |  peticao (64%)            |  inepcia (63%)           
```

## Usando o modelo:
O que precisa ser disponibilizado para o modelo funcionar:<br>
 :file_folder: `modelo_teste` <br>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - `VOCAB_BASE*.txt` - arquivo com termos e fragmentos que comp√µem o vocab <br>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - `VOCAB_TRADUTOR*.txt` - arquivo de transforma√ß√µes do tokenizados <br>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - `VOCAB_REMOVER*.txt` - arquivo de exclus√µes do tokenizados <br>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - `doc2vec*` - arquivos do modelo treinado <br>
 
 Coloque tudo em uma pasta com o nome que desejar e pronto. Esse √© um pacote do seu modelo. <br>

O modelo pode ser carregado facilmente:
 ```python 
 from util_doc2vec_facil import UtilDoc2VecFacil
 dv = UtilDoc2VecFacil(pasta_modelo=PASTA_MODELO)

frase1 = 'EXECU√á√ÉO POR T√çTULO EXTRAJUDICIAL DE HONOR√ÅRIO ADVOCAT√çCIO EMBARGOS ADJUDICA√á√ÉO PENHORAS'
frase2 = 'EMENTA SEGUROs de VIDA COBRAN√áA CUMULADA C PRETENS√ÉO INDENIZAT√ìRIA PRESCRI√á√ÉO RECONHECIDA'
frase3 = 'DE HONOR√ÅRIOS ADVOCAT√çCIOS EMBARGOS ADJUDICA√á√ÉO PENHORA EXECU√á√ÉO POR T√çTULO EXTRAJUDICIAL '
print('Frase1: ', frase1, '\nFrase2: ', frase2, '\n\t - Similaridade: ', dv.similaridade(frase1,frase2))
print('Frase1: ', frase1, '\nFrase3: ', frase3, '\n\t - Similaridade: ', dv.similaridade(frase1,frase3))        
print('\nTokens frase 1: ', dv.tokens_sentenca(frase1))
 ```
 
 <b>Resultado:</b>
 ```
Frase1:  EXECU√á√ÉO POR T√çTULO EXTRAJUDICIAL DE HONOR√ÅRIO ADVOCAT√çCIO EMBARGOS ADJUDICA√á√ÉO PENHORAS
Frase2:  EMENTA SEGUROs de VIDA COBRAN√áA CUMULADA C PRETENS√ÉO INDENIZAT√ìRIA PRESCRI√á√ÉO RECONHECIDA
         - Similaridade:  0.43190062046051025
Frase1:  EXECU√á√ÉO POR T√çTULO EXTRAJUDICIAL DE HONOR√ÅRIO ADVOCAT√çCIO EMBARGOS ADJUDICA√á√ÉO PENHORAS
Frase3:  DE HONOR√ÅRIOS ADVOCAT√çCIOS EMBARGOS ADJUDICA√á√ÉO PENHORA EXECU√á√ÉO POR T√çTULO EXTRAJUDICIAL
         - Similaridade:  0.46588313579559326

Tokens frase 1:  ['execucao', 'por', 'titulo', 'extrajudicial', 'de', 'honorario', 'advocaticio', 'embargos', 'adjudicacao', 'penhoras'] 
 ```

## Dicas de uso:
- gravar os vetores, textos e metadados dos documentos no ElasticSearch
- fazer pesquisas com More Like This, vetoriais e por proximidade de termos como disponibilizado no componente [PesquisaElasticFacil](https://github.com/luizanisio/PesquisaElasticFacil) em breve.

