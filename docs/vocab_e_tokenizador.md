
## Como funciona o Tokenizador Inteligente <a name="tokenizador">
  - Ao ser instanciado, o tokenizador busca os termos do vocab de treinamento contidos nos arquivos com padr√£o `VOCAB_BASE*.txt` (n√£o importa o case). Caso n√£o seja encontrado nenhum arquivo de termos, todos os termos dos documentos ser√£o considerados.
  - Voc√™ pode criar listas de termos que ser√£o exclu√≠dos do treinamento, basta estarem em arquivos com o padr√£o `VOCAB_REMOVIDO*.txt` - aqui geralmente ficam 'stopwords' ou termos que n√£o ajudam na diferencia√ß√£o dos documentos, bem como termos considerados "ru√≠dos" dos textos com OCR, por exemplo. Os termos contidos na lista de termos removidos n√£o s√£o fragmentados durante a tokeniza√ß√£o.
  - H√° um singularizador autom√°tico de termos. Dependendo da termina√ß√£o do termo, ele ser√° singularizado por regras simples de singulariza√ß√£o - m√©todo `singularizar( )` - e caso o resultado desse processamento esteja no vocab, o termo ficar√° no singular. Funciona para termos compostos tamb√©m. A ideia √© reduzir um pouco mais o vocab nesse passo. 
    - Exemplo: o termo `humanos` ser√° convertido em `humano` se o termo `humano` estiver no vocab. Termos no singular constantes no `VOCAB_REMOVIDO` fazem com que os termos do plural seram removidos tamb√©m. O resultado de todos os termos removidos pode ser conferido em `vocab_removido.log` gerado ao carregar o tokenizador ou o modelo.
  - Podem existir transformadores de termos nos arquivos com o padr√£o `VOCAB_TRADUTOR*.txt` que podem conter termos simples ou compostos que ser√£o convertidos em outros termos simples ou compostos, como ngramas por exempo. Veja [`NGramasFacil`](readme_ngramas.md) para mais detalhes.
  - Os tradutores funcionam antes da verifica√ß√£o dos termos do vocab. Todos os conjuntos de transforma√ß√£o s√£o inclu√≠dos automaticamente no vocab. 
  - Exemplo de configura√ß√£o:
    - `termo1 => termo2` - converte o `termo1` em `termo2` quando encontrado no texto (ex. `min => ministro`)
    - `termo1 termo2 => termo1_termo2` - converte o termo composto `termo1 termo2` em um termo √∫nico `termo1_termo2` (Ex. `processo penal => processo_penal`)
    - `termo1 termo2` - remove o termo composto `termo1 termo2` (Ex. `documento digital => ` ou `documento digital`)
  - Os tradutores podem ser usados para converter nomes de organiza√ß√µes em suas siglas, termos compostos em um termo √∫nicos (ngramas), corre√ß√µes ortogr√°ficas de termos importantes, e at√© termos conhecidos como id√™nticos convertendo para a sua forma mais usual. √â importante ressaltar que quanto maior o n√∫mero de termos para transforma√ß√£o, maior o tempo de pr√©-processamento. A transforma√ß√£o e limpeza ocorrem apenas uma vez e um arquivo `.clr` √© criado para cada arquivo `.txt` com o documento pronto para treinamento.
    - Est√° dispon√≠vel um gerador de bigramas e quadrigramas aqui [`NGramasFacil`](readme_ngramas.md) para gerar sugest√µes autom√°ticas de termos que podem ser unificados.
  
> üí° <sub>A ideia de criar v√°rios arquivos √© para organizar por dom√≠nios. Pode-se, por exemplo, criar um arquivo `VOCAB_BASE portugues.txt` com termos que far√£o parte de v√°rios modelos, um arquivo `VOCAB_BASE direito.txt` com termos do direito que ser√£o somados ao primeiro no treinamento, um arquivo `VOCAB_BASE direito fragmentos.txt` com fragmentos (`stemmer` + `sufixos`) de termos do direito, e assim por diante. Facilitando evolu√ß√µes futuras dos vocabul√°rios.</sub><br>
  <sub>Pode-se realizar o treinamento sem nenhuma configura√ß√£o de vocab, ent√£o todos os termos ser√£o treinados. A ideia de criar um vocab √© poder ter algum controle do que ser√° treinado e limpar textos ocerizados que possuem muitos erros e podem aumentar muito o vocab de treinamento com ru√≠dos.</sub>

## Arquivo de curadoria para cria√ß√£o do vocab
 Ao rodar o c√≥digo `python util_doc2vec_vocab_facil.py -pasta ./meu_modelo`, ser√° criado um arquivo de curadoria de termos `curadoria_planilha_vocab.xlsx` com os termos encontrados nos textos da pasta `textos_vocab` ou, se essa pasta n√£o existir, ser√° usada a pasta `textos_treino`. 
 - o objetivo do arquivo de curadoria √© permitir identificar os termos que ser√£o treinados e a import√¢ncia deles nos documentos (TFIDF, tamanho, frequ√™ncia etc). Pode-se interferir no treinamento retirando termos ou indicando os termos que ser√£o treinados. Pode-se realizar um treinamento com todos os termos dos documentos, nesse caso n√£o h√° necessidade de identificar termos que dever√£o entrar ou sair do treinamento (basta treinar o modelo sem configurar os arquivos de vocab).
 - voc√™ pode criar a planilha de curadoria com todos os textos que ser√£o treinados - `textos-treino`, ou com uma amostra dos textos para fazer uma an√°lise dos termos mais relevantes de forma mais r√°pida - `textos-vocab`. 
 - outra forma de criar uma lista de termos para configurar o vocab de treinamento √© colocar diversos documentos relevantes na pasta `textos-vocab`, incluindo gram√°ticas, lista de termos e textos t√©cnicos com palavras relacionadas ao corpus desejado (psicologia, medicina, legisla√ß√£o, administra√ß√£o, etc). Esse site permite uma an√°lise muito boa de termos e suas caracter√≠sticas, bem como encontrar novos termos derivados de outros termos [`Dicio`](https://www.dicio.com.br/), aqui temos [`Leis`](http://www4.planalto.gov.br/legislacao/portal-legis/legislacao-1/codigos-1) e documentos Jur√≠dicos nos sites do [`STF`](https://www.stf.jus.br) ou [`STJ`](https://www.stj.jus.br).
 - depois de criar a lista de termos relevantes para o corpus, pode-se incluir eles em um arquivo `VOCAB_BASE termos t√©cnicos.txt` e rodar novamente a planilha de curadoria para a pasta de treino - `textos-treino`. Com isso vai aparecer na planilha se o termo encontrado est√° ou n√£o no vocab configurado at√© o momento. √â mais uma informa√ß√£o para an√°lise dos termos para cria√ß√£o do vocab final de treinamento.
 - Alguns termos podem n√£o ser t√£o importantes para o dom√≠nio escolhido, mas podem ser importantes para o contexto. Esses termos podem compor o dicion√°rio em forma de `stemmer` + `sufixo`. Aos termos n√£o encontrados no dicion√°rio durante a tokeniza√ß√£o para treinamento, ser√° aplicado o [`stemmer`](https://www.nltk.org/_modules/nltk/stem/snowball.html)  com o sufixo ap√≥s o stemmer. Caso o stemmer esteja no vocab de treinamento, este ser√° usado. O sufixo √© opcional e ser√° inclu√≠do se estiver no vocab e se o prefixo estiver no vocab de treinamento tamb√©m.
 - Essa combina√ß√£o de termos completos e fragmentos (stemmer + sufixo) possibilita criar palavras por combina√ß√£o ao submeter um documento novo ao modelo que contenha termos fora do vocam de treinamento. Pode ser interessante manter o stemmer apenas dos termos mais relevantes para o contexto do treinamento.
 - Opcionalmente pode-se usar o par√¢metro `-treino` para gerar o arquivo de curadoria com base nos arquivos da pasta `texto_treino`, ou o par√¢metro `-teste` para os arquivos da pasta `texto_teste`. 
 - o par√¢metro `-vocab_treino` pode ser √∫til para comparar os termos dos textos com os termos realmente treinados no vocab ap√≥s o in√≠cio do treinamento. Pode-se combinar os par√¢metros `-treino -vocab_treino` ou `-teste -vocab_treino`. Com isso √© poss√≠vel avaliar rapidamente o comportamento do vocabul√°rio selecionado para tokeniza√ß√£o at√© o vocabul√°rio utilizado pelo `Gensim` no treinamento. O arquivo `vocab_treino.txt` √© criado ap√≥s a primeira √©poca de treinamento.
> :bulb: <sub> Nota: √© importante ressaltar que ap√≥s modelo ser gerado, apenas os termos contidos no vocabul√°rio do modelo ser√£o usados na vetoriza√ß√£o. Os termos realmente treinados podem ser visualizados no arquivo `vocab_treino.txt` gerado ap√≥s a primeira √©poca de treinamento.</sub>  
   
 - <b>Exemplo</b>: `engloba` pode ser composta por `englob` `#a`, e outras forma√ß√µes podem ocorrer como `englob` `#ada`, `englob` `#adamente`, `englob` `#adas` caso esses  fragmentos estejam dispon√≠veis no vocabul√°rio de treinamento.
   - O vocab de treinamento n√£o precisa do `#` antes do sufixo, apenas dos fragmentos. Mas durante o treinamento os fragmentos usados como sufixo iniciar√£o com `#` para facilitar sua identifica√ß√£o e diferenciar dos termos principais no modelo final.
 - <b>Exemplo de tokeniza√ß√£o com termos simples, compostos e fragmentos</b>: 
   ```
   ['atendiam_testemunha', 'seu', 'depoimento', 'apesar', 'de', 'trazer', 'algumas', 'impreciso', '#es', 'sobre', 'os', 'fatos', 'atend', '#o', 'se', 'os', 'jurados', 'as', 'provas', 'produzidas', 'em', 'plenari', '#os']
   ```

- Veja o [`passo a passo`](passo_a_passo_facil.md) para criar o vocabul√°rio de treinamento de acordo com o cen√°rio desejado e realizar o treinamento propriamente dito.

### Exemplo de arquivo `curadoria_planilha_vocab.xlsx` de curadoria de termos:
![recorte curadoria_planilha_vocab.xlsx](../exemplos/img_corte_plan_curadoria.png?raw=true "Recorte planilha curadoria")

> üí° Notas sobre as colunas: 
> - `TFIDF` - cont√©m a m√©dia dos pesos que o termo teve nos documentos - Saiba mais sobre [`TFIDF`](https://www.ti-enxame.com/pt/python/interpretar-um-resumo-das-pontuacoes-das-palavras-do-tf-idf-nos-documentos/829990829/), ou [`TFIDF - beatles`](https://iyzico.engineering/how-to-calculate-tf-idf-term-frequency-inverse-document-frequency-from-the-beatles-biography-in-c4c3cd968296).
> - `TAMANHO` - √© o tamanho do termo
> - `QTD` - √© a quantidade de vezes que o termo apareceu no corpus
> - `QTD_DOCS` - √© a quantidade de documentos onde o termo apareceu
> - `COMPOSTO` Sim / N√£o - indica se o termo √© composto 
> - `VOCAB` - indica se o termo est√° presente no vocab principal, se est√° presente quando fragmentado, se √© composto, se √© removido do vocab ou se n√£o est√° presente no vocab.
> - `ESTRANHO` Sim / N√£o - termos sem vogais ou com consoantes/vogais com v√°rias repeti√ß√µes
> - Ao final s√£o inclu√≠das algumas colunas indicando a posi√ß√£o das colunas `TFIDF`, `TAMANHO`, `QTD` e `QTD_DOCS` no BoxPlot de cada coluna.

